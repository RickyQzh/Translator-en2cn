{
    "batch_size": 64,
    "epochs": 30,
    "learning_rate": 0.001,
    "d_model": 128,
    "num_heads": 4,
    "num_encoder_layers": 6,
    "num_decoder_layers": 6,
    "d_ff": 512,
    "dropout": 0.2,
    "label_smoothing": 0.1,
    "patience": 5,
    "ablation_keys": [
        "d_model",
        "num_heads",
        "d_ff"
    ]
}